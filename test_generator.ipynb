{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edabk-lab/miniconda3/envs/cgpy/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchgeometry as tgm\n",
    "import sys\n",
    "import os\n",
    "# sys.path.append(os.path.abspath('..'))  # Assuming your notebook is one level down\n",
    "from utils.gan_utils import get_bone_lengthbypose3d, get_bone_unit_vecbypose3d, \\\n",
    "    get_pose3dbyBoneVec, blaugment9to15\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, linear_size):\n",
    "        super(Linear, self).__init__()\n",
    "        self.l_size = linear_size\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        self.w1 = nn.Linear(self.l_size, self.l_size)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(self.l_size)\n",
    "\n",
    "        self.w2 = nn.Linear(self.l_size, self.l_size)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(self.l_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.w1(x)\n",
    "        y = self.batch_norm1(y)\n",
    "        y = self.relu(y)\n",
    "\n",
    "        y = self.w2(y)\n",
    "        y = self.batch_norm2(y)\n",
    "        y = self.relu(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "######################################################\n",
    "###################  START  ##########################\n",
    "######################################################\n",
    "class PoseGenerator(nn.Module):\n",
    "    def __init__(self, input_size=16 * 3):\n",
    "        super(PoseGenerator, self).__init__()\n",
    "        self.BAprocess = BAGenerator(input_size=input_size)\n",
    "        self.BLprocess = BLGenerator(input_size=input_size, blr_tanhlimit=2e-1)\n",
    "        self.RTprocess = RTGenerator(input_size=input_size)\n",
    "\n",
    "    def forward(self, inputs_3d):\n",
    "        '''\n",
    "        input: 3D pose\n",
    "        :param inputs_3d: nx16x3, with hip root\n",
    "        :return: nx16x3\n",
    "        '''\n",
    "        pose_ba, ba_diff = self.BAprocess(inputs_3d)  # diff may be used for div loss\n",
    "        pose_bl, blr = self.BLprocess(inputs_3d, pose_ba)  # blr used for debug\n",
    "        pose_rt, rt = self.RTprocess(inputs_3d, pose_bl)  # rt=(r,t) used for debug\n",
    "\n",
    "        return {'pose_ba': pose_ba,\n",
    "                'ba_diff': ba_diff,\n",
    "                'pose_bl': pose_bl,\n",
    "                'blr': blr,\n",
    "                'pose_rt': pose_rt,\n",
    "                'rt': rt}\n",
    "\n",
    "\n",
    "######################################################\n",
    "###################  END  ############################\n",
    "######################################################\n",
    "\n",
    "class BAGenerator(nn.Module):\n",
    "    def __init__(self, input_size, noise_channle=48, linear_size=256, num_stage=2, p_dropout=0.5):\n",
    "        super(BAGenerator, self).__init__()\n",
    "\n",
    "        self.linear_size = linear_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.num_stage = num_stage\n",
    "        self.noise_channle = noise_channle\n",
    "\n",
    "        # 3d joints\n",
    "        self.input_size = input_size  # 16 * 3\n",
    "\n",
    "        # process input to linear size\n",
    "        self.w1 = nn.Linear(self.input_size + self.noise_channle, self.linear_size)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(self.linear_size)\n",
    "\n",
    "        self.linear_stages = []\n",
    "        for l in range(num_stage):\n",
    "            self.linear_stages.append(Linear(self.linear_size))\n",
    "        self.linear_stages = nn.ModuleList(self.linear_stages)\n",
    "\n",
    "        # post processing\n",
    "        self.w2 = nn.Linear(self.linear_size, self.input_size - 3)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, inputs_3d):\n",
    "        '''\n",
    "        :param inputs_3d: nx16x3.\n",
    "        :return: nx16x3\n",
    "        '''\n",
    "        # convert 3d pose to root relative\n",
    "        root_origin = inputs_3d[:, :1, :] * 1.0\n",
    "        x = inputs_3d - inputs_3d[:, :1, :]  # x: root relative\n",
    "\n",
    "        # extract length, unit bone vec\n",
    "        bones_unit = get_bone_unit_vecbypose3d(x)\n",
    "        bones_length = get_bone_lengthbypose3d(x)\n",
    "\n",
    "        # pre-processing\n",
    "        x = x.view(x.size(0), -1)\n",
    "        noise = torch.randn(x.shape[0], self.noise_channle, device=x.device)\n",
    "\n",
    "        y = self.w1(torch.cat((x, noise), dim=1))\n",
    "        y = self.batch_norm1(y)\n",
    "        y = self.relu(y)\n",
    "\n",
    "        # linear layers\n",
    "        for i in range(self.num_stage):\n",
    "            y = self.linear_stages[i](y)\n",
    "\n",
    "        y = self.w2(y)\n",
    "        y = y.view(x.size(0), -1, 3)\n",
    "\n",
    "        # modify the bone angle with length unchanged.\n",
    "        modifyed = bones_unit + y\n",
    "        modifyed_unit = modifyed / torch.norm(modifyed, dim=2, keepdim=True)\n",
    "\n",
    "        # fix bone segment from pelvis to thorax to avoid pure rotation of whole body without ba changes.\n",
    "        tmp_mask = torch.ones_like(bones_unit)\n",
    "        tmp_mask[:, [6, 7], :] = 0.\n",
    "        modifyed_unit = modifyed_unit * tmp_mask + bones_unit * (1 - tmp_mask)\n",
    "\n",
    "        cos_angle = torch.sum(modifyed_unit * bones_unit, dim=2)\n",
    "        ba_diff = 1 - cos_angle\n",
    "\n",
    "        modifyed_bone = modifyed_unit * bones_length\n",
    "\n",
    "        # convert bone vec back to 3D pose\n",
    "        out = get_pose3dbyBoneVec(modifyed_bone) + root_origin\n",
    "\n",
    "        return out, ba_diff\n",
    "\n",
    "\n",
    "class RTGenerator(nn.Module):\n",
    "    def __init__(self, input_size, noise_channle=48, linear_size=256, num_stage=2, p_dropout=0.5):\n",
    "        super(RTGenerator, self).__init__()\n",
    "        '''\n",
    "        :param input_size: n x 16 x 3\n",
    "        :param output_size: R T 3 3 -> get new pose for pose 3d projection.\n",
    "        '''\n",
    "        self.linear_size = linear_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.num_stage = num_stage\n",
    "        self.noise_channle = noise_channle\n",
    "\n",
    "        # 3d joints\n",
    "        self.input_size = input_size  # 16 * 3\n",
    "\n",
    "        # process input to linear size -> for R\n",
    "        self.w1_R = nn.Linear(self.input_size + self.noise_channle, self.linear_size)\n",
    "        self.batch_norm_R = nn.BatchNorm1d(self.linear_size)\n",
    "\n",
    "        self.linear_stages_R = []\n",
    "        for l in range(num_stage):\n",
    "            self.linear_stages_R.append(Linear(self.linear_size))\n",
    "        self.linear_stages_R = nn.ModuleList(self.linear_stages_R)\n",
    "\n",
    "        # process input to linear size -> for T\n",
    "        self.w1_T = nn.Linear(self.input_size + self.noise_channle, self.linear_size)\n",
    "        self.batch_norm_T = nn.BatchNorm1d(self.linear_size)\n",
    "\n",
    "        self.linear_stages_T = []\n",
    "        for l in range(num_stage):\n",
    "            self.linear_stages_T.append(Linear(self.linear_size))\n",
    "        self.linear_stages_T = nn.ModuleList(self.linear_stages_T)\n",
    "\n",
    "        # post processing\n",
    "        self.w2_R = nn.Linear(self.linear_size, 3)\n",
    "        self.w2_T = nn.Linear(self.linear_size, 3)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        # self.dropout = nn.Dropout(self.p_dropout)\n",
    "\n",
    "    def forward(self, inputs_3d, augx):\n",
    "        '''\n",
    "        :param inputs_3d: nx16x3\n",
    "        :return: nx16x3\n",
    "        '''\n",
    "        # convert 3d pose to root relative\n",
    "        root_origin = inputs_3d[:, :1, :] * 1.0\n",
    "        x = inputs_3d - inputs_3d[:, :1, :]  # x: root relative\n",
    "\n",
    "        # pre-processing\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # caculate R\n",
    "        noise = torch.randn(x.shape[0], self.noise_channle, device=x.device)\n",
    "        r = self.w1_R(torch.cat((x, noise), dim=1))\n",
    "        r = self.batch_norm_R(r)\n",
    "        r = self.relu(r)\n",
    "        # r = self.dropout(r)\n",
    "        for i in range(self.num_stage):\n",
    "            r = self.linear_stages_R[i](r)\n",
    "\n",
    "        r = self.w2_R(r)\n",
    "        r = nn.Tanh()(r) * 3.1415\n",
    "        r = r.view(x.size(0), 3)\n",
    "        rM = tgm.angle_axis_to_rotation_matrix(r)[..., :3, :3]  # Nx4x4->Nx3x3 rotation matrix\n",
    "\n",
    "        # caculate T\n",
    "        noise = torch.randn(x.shape[0], self.noise_channle, device=x.device)\n",
    "        t = self.w1_T(torch.cat((x, noise), dim=1))\n",
    "        t = self.batch_norm_T(t)\n",
    "        t = self.relu(t)\n",
    "        for i in range(self.num_stage):\n",
    "            t = self.linear_stages_T[i](t)\n",
    "\n",
    "        t = self.w2_T(t)\n",
    "        t[:, 2] = t[:, 2].clone() * t[:, 2].clone()\n",
    "        t = t.view(x.size(0), 1, 3)  # Nx1x3 translation t\n",
    "\n",
    "        # operat RT on original data - augx\n",
    "        augx = augx - augx[:, :1, :]  # x: root relative\n",
    "        augx = augx.permute(0, 2, 1).contiguous()\n",
    "        augx_r = torch.matmul(rM, augx)\n",
    "        augx_r = augx_r.permute(0, 2, 1).contiguous()\n",
    "        augx_rt = augx_r + t\n",
    "\n",
    "        return augx_rt, (r, t)  # return r t for debug\n",
    "\n",
    "\n",
    "class BLGenerator(nn.Module):\n",
    "    def __init__(self, input_size, noise_channle=48, linear_size=256, num_stage=2, p_dropout=0.5, blr_tanhlimit=0.2):\n",
    "        super(BLGenerator, self).__init__()\n",
    "        '''\n",
    "        :param input_size: n x 16 x 3\n",
    "        :param output_size: R T 3 3 -> get new pose for pose 3d projection.\n",
    "        '''\n",
    "        self.linear_size = linear_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.num_stage = num_stage\n",
    "        self.noise_channle = noise_channle\n",
    "        self.blr_tanhlimit = blr_tanhlimit\n",
    "\n",
    "        # 3d joints\n",
    "        self.input_size = input_size + 15  # 16 * 3 + bl\n",
    "\n",
    "        # process input to linear size -> for R\n",
    "        self.w1_BL = nn.Linear(self.input_size + self.noise_channle, self.linear_size)\n",
    "        self.batch_norm_BL = nn.BatchNorm1d(self.linear_size)\n",
    "\n",
    "        self.linear_stages_BL = []\n",
    "        for l in range(num_stage):\n",
    "            self.linear_stages_BL.append(Linear(self.linear_size))\n",
    "        self.linear_stages_BL = nn.ModuleList(self.linear_stages_BL)\n",
    "\n",
    "        # post processing\n",
    "        self.w2_BL = nn.Linear(self.linear_size, 9)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, inputs_3d, augx):\n",
    "        '''\n",
    "        :param inputs_3d: nx16x3\n",
    "        :return: nx16x3\n",
    "        '''\n",
    "        # convert 3d pose to root relative\n",
    "        root_origin = inputs_3d[:, :1, :] * 1.0\n",
    "        x = inputs_3d - inputs_3d[:, :1, :]  # x: root relative\n",
    "\n",
    "        # pre-processing\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # caculate blr\n",
    "        bones_length_x = get_bone_lengthbypose3d(x.view(x.size(0), -1, 3)).squeeze(2)  # 0907\n",
    "        noise = torch.randn(x.shape[0], self.noise_channle, device=x.device)\n",
    "        blr = self.w1_BL(torch.cat((x, bones_length_x, noise), dim=1))\n",
    "        blr = self.batch_norm_BL(blr)\n",
    "        blr = self.relu(blr)\n",
    "        for i in range(self.num_stage):\n",
    "            blr = self.linear_stages_BL[i](blr)\n",
    "\n",
    "        blr = self.w2_BL(blr)\n",
    "\n",
    "        # create a mask to filter out 8th blr to avoid ambiguity (tall person at far may have same 2D with short person at close point).\n",
    "        tmp_mask = torch.from_numpy(np.array([[1, 1, 1, 1, 0, 1, 1, 1, 1]]).astype('float32')).to(blr.device)\n",
    "        blr = blr * tmp_mask\n",
    "        # operate BL modification on original data\n",
    "        blr = nn.Tanh()(blr) * self.blr_tanhlimit  # allow +-20% length change.\n",
    "\n",
    "        bones_length = get_bone_lengthbypose3d(augx)\n",
    "        augx_bl = blaugment9to15(augx, bones_length, blr.unsqueeze(2))\n",
    "        return augx_bl, blr  # return blr for debug\n",
    "\n",
    "\n",
    "def random_bl_aug(x):\n",
    "    '''\n",
    "    :param x: nx16x3\n",
    "    :return: nx16x3\n",
    "    '''\n",
    "    bl_15segs_templates_mdifyed = np.load('./data_extra/bone_length_npy/hm36s15678_bl_templates.npy')\n",
    "\n",
    "    # convert 3d pose to root relative\n",
    "    root = x[:, :1, :] * 1.0\n",
    "    x = x - x[:, :1, :]\n",
    "\n",
    "    # extract length, unit bone vec\n",
    "    bones_unit = get_bone_unit_vecbypose3d(x)\n",
    "\n",
    "    # prepare a bone length list for augmentation.\n",
    "    tmp_idx = np.random.choice(bl_15segs_templates_mdifyed.shape[0], x.shape[0])\n",
    "    bones_length = torch.from_numpy(bl_15segs_templates_mdifyed[tmp_idx].astype('float32')).unsqueeze(2)\n",
    "\n",
    "    modifyed_bone = bones_unit * bones_length.to(x.device)\n",
    "\n",
    "    # convert bone vec back to pose3d\n",
    "    out = get_pose3dbyBoneVec(modifyed_bone)\n",
    "\n",
    "    return out + root  # return the pose with position information.\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # test = Project_cam3d_to_cam2d()\n",
    "#     random_bl_aug(None)\n",
    "#     print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Total parameters: 1.18M\n"
     ]
    }
   ],
   "source": [
    "model_G = PoseGenerator(16 * 3).to(torch.device(\"cuda:0\"))\n",
    "model_G.apply(init_weights)\n",
    "print(\"==> Total parameters: {:.2f}M\".format(sum(p.numel() for p in model_G.parameters()) / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Total parameters: 1.08M\n",
      "==> Total parameters: 0.04M\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "num_joints=16\n",
    "from models_poseaug.PosDiscriminator import Pos2dDiscriminator, Pos3dDiscriminator\n",
    "# discriminator for 3D\n",
    "model_d3d = Pos3dDiscriminator(num_joints).to(device)\n",
    "model_d3d.apply(init_weights)\n",
    "print(\"==> Total parameters: {:.2f}M\".format(sum(p.numel() for p in model_d3d.parameters()) / 1000000.0))\n",
    "\n",
    "# discriminator for 2D\n",
    "model_d2d = Pos2dDiscriminator(num_joints).to(device)\n",
    "model_d2d.apply(init_weights)\n",
    "print(\"==> Total parameters: {:.2f}M\".format(sum(p.numel() for p in model_d2d.parameters()) / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mthis code is used for prepare data loader\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     15\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh36m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[43margs\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_preparation\u001b[39m(args):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    load the h36m dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    generate data loader for training posenet, poseaug, and cross-data evaluation\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "\n",
    "import os.path as path\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from common.data_loader import PoseDataSet, PoseBuffer, PoseTarget\n",
    "from utils.data_utils import fetch, read_3d_data, create_2d_data\n",
    "\n",
    "'''\n",
    "this code is used for prepare data loader\n",
    "'''\n",
    "\n",
    "dataset = \"h36m\"\n",
    "args\n",
    "def data_preparation(args):\n",
    "    \"\"\"\n",
    "    load the h36m dataset\n",
    "    generate data loader for training posenet, poseaug, and cross-data evaluation\n",
    "    \"\"\"\n",
    "    dataset_path = path.join('data', 'data_3d_' + args.dataset + '.npz')\n",
    "    if args.dataset == 'h36m':\n",
    "        from common.h36m_dataset import Human36mDataset, TEST_SUBJECTS\n",
    "        dataset = Human36mDataset(dataset_path)\n",
    "        if args.s1only:\n",
    "            subjects_train = ['S1']\n",
    "        else:\n",
    "            subjects_train = ['S1', 'S5', 'S6', 'S7', 'S8']\n",
    "        subjects_test = TEST_SUBJECTS\n",
    "    else:\n",
    "        raise KeyError('Invalid dataset')\n",
    "\n",
    "    print('==> Loading 3D data...')\n",
    "    dataset = read_3d_data(dataset)\n",
    "\n",
    "    print('==> Loading 2D detections...')\n",
    "    keypoints = create_2d_data(path.join('data', 'data_2d_' + args.dataset + '_' + args.keypoints + '.npz'), dataset)\n",
    "\n",
    "    action_filter = None if args.actions == '*' else args.actions.split(',')\n",
    "    if action_filter is not None:\n",
    "        action_filter = map(lambda x: dataset.define_actions(x)[0], action_filter)\n",
    "        print('==> Selected actions: {}'.format(action_filter))\n",
    "\n",
    "    stride = args.downsample\n",
    "\n",
    "    ############################################\n",
    "    # general 2D-3D pair dataset\n",
    "    ############################################\n",
    "    poses_train, poses_train_2d, actions_train, cams_train = fetch(subjects_train, dataset, keypoints, action_filter,\n",
    "                                                                   stride)\n",
    "    poses_valid, poses_valid_2d, actions_valid, cams_valid = fetch(subjects_test, dataset, keypoints, action_filter,\n",
    "                                                                   stride)\n",
    "    # prepare train loader for detected 2D.\n",
    "    train_det2d3d_loader = DataLoader(PoseDataSet(poses_train, poses_train_2d, actions_train, cams_train),\n",
    "                                      batch_size=args.batch_size,\n",
    "                                      shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    # prepare train loader for GT 2D - 3D, which will update by using projection.\n",
    "    train_gt2d3d_loader = DataLoader(PoseDataSet(poses_train, poses_train_2d, actions_train, cams_train),\n",
    "                                     batch_size=args.batch_size,\n",
    "                                     shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    valid_loader = DataLoader(PoseDataSet(poses_valid, poses_valid_2d, actions_valid, cams_valid),\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    ############################################\n",
    "    # data loader for GAN training\n",
    "    ############################################\n",
    "    target_2d_loader = DataLoader(PoseTarget(poses_train_2d),\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "    target_3d_loader = DataLoader(PoseTarget(poses_train),\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    ############################################\n",
    "    # prepare cross dataset validation\n",
    "    ############################################\n",
    "    # 3DHP -  2929 version\n",
    "    mpi3d_npz = np.load('data_extra/test_set/test_3dhp.npz')    # this is the 2929 version\n",
    "    tmp = mpi3d_npz\n",
    "    mpi3d_loader = DataLoader(PoseBuffer([tmp['pose3d']], [tmp['pose2d']]),\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    return {\n",
    "        'dataset': dataset,\n",
    "        'train_det2d3d_loader': train_det2d3d_loader,\n",
    "        'train_gt2d3d_loader': train_gt2d3d_loader,\n",
    "        'target_2d_loader': target_2d_loader,\n",
    "        'target_3d_loader': target_3d_loader,\n",
    "        'H36M_test': valid_loader,\n",
    "        'mpi3d_loader': mpi3d_loader,\n",
    "        'action_filter': action_filter,\n",
    "        'subjects_test': subjects_test,\n",
    "        'keypoints': keypoints,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_baseline.gcn.sem_gcn import SemGCN\n",
    "from function_poseaug.data_preparation import data_preparation\n",
    "print('==> Loading dataset...')\n",
    "data_dict = data_preparation(args)\n",
    "adj = adj_mx_from_skeleton(dataset.skeleton())\n",
    "model_sem_gcn = SemGCN(SemGCN(adj, 128, num_layers=4, p_dropout=0., nodes_group=None).to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
